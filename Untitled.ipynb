{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建模程序 \n",
    "只用跑一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/devkits/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.611 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['信息产业' '医养健康' '文化产业' '旅游产业' '旧动能' '海洋经济' '现代农业' '现代金融' '能源原材料' '能源新材料'\n",
      " '高端化工' '高端装备制造']\n",
      "Dictionary(3107 unique tokens: ['GC2', '三类', '专用设备', '业务', '为准']...)\n",
      "[(12, 0.9933333)]\n",
      "1320\n",
      "(1320, 25) (1320, 12)\n",
      "Epoch 1/10\n",
      "1320/1320 [==============================] - 0s 370us/step - loss: 0.9757 - acc: 0.8455\n",
      "Epoch 2/10\n",
      "1320/1320 [==============================] - 0s 265us/step - loss: 0.5643 - acc: 0.8765\n",
      "Epoch 3/10\n",
      "1320/1320 [==============================] - 0s 288us/step - loss: 0.5561 - acc: 0.8765\n",
      "Epoch 4/10\n",
      "1320/1320 [==============================] - 0s 373us/step - loss: 0.5624 - acc: 0.8765\n",
      "Epoch 5/10\n",
      "1320/1320 [==============================] - 0s 307us/step - loss: 0.5693 - acc: 0.8765\n",
      "Epoch 6/10\n",
      "1320/1320 [==============================] - 0s 283us/step - loss: 0.5897 - acc: 0.8765\n",
      "Epoch 7/10\n",
      "1320/1320 [==============================] - 0s 272us/step - loss: 0.5907 - acc: 0.8765\n",
      "Epoch 8/10\n",
      "1320/1320 [==============================] - 0s 284us/step - loss: 0.5930 - acc: 0.8765\n",
      "Epoch 9/10\n",
      "1320/1320 [==============================] - 0s 269us/step - loss: 0.6123 - acc: 0.8765\n",
      "Epoch 10/10\n",
      "1320/1320 [==============================] - 0s 293us/step - loss: 0.6109 - acc: 0.8765\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import pickle\n",
    "def get_stop_words():\n",
    "    '''停用词表'''\n",
    "    with open('data/stop_words_utf8.txt') as f:\n",
    "        content = f.readlines()\n",
    "        stopwords = [w.strip() for w in content]\n",
    "        return stopwords\n",
    "\n",
    "# 全角转换成半角\n",
    "def strQ2B(ustring):\n",
    "    '''全角转半角\n",
    "    ustring : 需要转换的字符串\n",
    "    '''\n",
    "    ss = ''\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # 全角空格直接转换\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全角字符（除空格）根据关系转化\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss = ss + rstring\n",
    "    return ss\n",
    "# 对corpus中每个文章分词后滤出停用词\n",
    "def cut(doc):\n",
    "    '''分词'''\n",
    "    content = list(jieba.cut(doc))\n",
    "    stopwords = get_stop_words()\n",
    "    return '/'.join([w for w in content if w not in stopwords and w!=' '])\n",
    "\n",
    "def handle_desc(desc):\n",
    "    '''对企业描述分词'''\n",
    "    desc = strQ2B(desc)\n",
    "    cut = jieba.cut(desc)\n",
    "    stopwords = get_stop_words()\n",
    "    return [w for w in cut if w not in stopwords and w!=' ']\n",
    "\n",
    "def getLDA(df,topic_num):\n",
    "    from gensim.models import LdaMulticore\n",
    "    from gensim.corpora import Dictionary\n",
    "    # gensim\n",
    "    dictionary = Dictionary(df[\"经营业务范围\"])\n",
    "    print(dictionary)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in df[\"经营业务范围\"]]\n",
    "    lda = LdaMulticore(corpus=corpus,  # LDA训练语料\n",
    "                   id2word=dictionary, # id到单词的映射表\n",
    "                   num_topics=topic_num)      # LDA主题数量 \n",
    "    return lda,corpus,dictionary\n",
    "\n",
    "def get_topic_distribute(lda,doc):\n",
    "    return lda[doc]\n",
    "\n",
    "def get_all_doc_topic(df):\n",
    "    lda_matrix = np.zeros((df[\"经营业务范围\"].shape[0],topic_num),dtype='float64')\n",
    "    for index,doc in enumerate(corpus):\n",
    "        topics = get_topic_distribute(lda,corpus[index])\n",
    "        for topic_tuple in topics:\n",
    "            lda_matrix[index,topic_tuple[0]] = topic_tuple[1]\n",
    "    return lda_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inputdf = pd.read_csv(\"newdata/input.csv\",index_col=0)\n",
    "    inputdf[\"经营业务范围\"] = inputdf[\"经营业务范围\"].apply(cut)\n",
    "    inputdf[\"经营业务范围\"] = inputdf[\"经营业务范围\"].apply(lambda x:x.split(\"/\"))\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    inputdf[\"label\"] = le.fit_transform(inputdf[\"label\"])\n",
    "    print(le.classes_)\n",
    "    topic_num = 25\n",
    "    lda,corpus,dictionary = getLDA(inputdf,topic_num)\n",
    "    #lda.print_topics()\n",
    "    print(get_topic_distribute(lda,corpus[0]))\n",
    "    print(len(corpus))\n",
    "    # 所有样本主题分布\n",
    "    all_topic = get_all_doc_topic(inputdf)\n",
    "    x = all_topic\n",
    "    y = pd.get_dummies(inputdf[\"label\"])\n",
    "    print(x.shape,y.shape)\n",
    "    network = models.Sequential()\n",
    "    # input_shape : 输入张量的形状, (28*28,)表示1维度向量\n",
    "    network.add(layers.Dense(32,activation='relu',input_shape=(x.shape[1],)))\n",
    "    network.add(layers.Dense(len(le.classes_),activation='softmax'))\n",
    "    # 4. 编译\n",
    "    network.compile(optimizer = 'rmsprop',\n",
    "                   loss = 'categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "    # 5. 训练模型\n",
    "    network.fit(x,y,epochs=10,batch_size=2)\n",
    "    with open('newdata/dict_save', 'wb') as f:                     \n",
    "        picklestring = pickle.dump(dictionary, f)\n",
    "    with open('newdata/labelestimeter', 'wb') as f:                     \n",
    "        picklestring = pickle.dump(le, f)\n",
    "    #保存lda模型\n",
    "    lda.save('newdata/lda.model')\n",
    "    network.save('newdata/my_model.h5') # 保存模型\n",
    "    network.save_weights('newdata/my_model_weights.h5') # 保存参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试\n",
    "tableau调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['红头文件可修改..']\n",
      "山东省\n",
      "['红头文件可修改..']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/devkits/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': '旧动能',\n",
       " '经营范围': '道路货物运输(普通货运);三类汽车维修(车身清洁维护);第一类压力容器、第二类低中压容器的设计、制造、销售,工业氧气(以上经营项目有效期限以许可证为准);金属成型机床设备、金属切削机床设备、工业自动控制系统装置、铸造机械设备、金属切割及焊接设备、建材及环境保护专用设备、机床附件、配电开关控制设备、塑料工业设备、包装机械设备、模具的设计、制造、销售;机床设备安装调试、维修改造;A级起重机械安装、GC2压力管道安装(以上凭资质证经营);机械零部件加工;金属材料、铸件、五金交电、橡胶制品、木制品、工夹量仪、汽车、汽车配件的销售;进出口业务;装卸服务;机械设备技术开发;企业管理咨询;计算机信息技术服务;软件开发;检测技术服务;经济贸易代理;职业技能鉴定;房屋租赁;场地租赁;物业管理服务;会议会展服务;分支机构经营:金属材料的焊接、锻造和热处理;提供培训场地、住宿,餐饮,酒水、卷烟的零售(以上凭许可证经营)。(依法须经批准的项目,经相关部门批准后方可开展经营活动)。',\n",
       " '所属城市': '山东省',\n",
       " '公司名称': '济南二机床集团有限公司技术中心',\n",
       " '红头文件描述项目': '红头文件可修改..'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "from keras.models import load_model\n",
    "\n",
    "def get_stop_words():\n",
    "    with open('data/stop_words_utf8.txt') as f:\n",
    "        content = f.readlines()\n",
    "        stopwords = [w.strip() for w in content]\n",
    "        return stopwords\n",
    "\n",
    "# 全角转换成半角\n",
    "def strQ2B(ustring):\n",
    "    '''全角转半角\n",
    "    ustring : 需要转换的字符串\n",
    "    '''\n",
    "    ss = ''\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # 全角空格直接转换\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全角字符（除空格）根据关系转化\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss = ss + rstring\n",
    "    return ss\n",
    "# 对corpus中每个文章分词后滤出停用词\n",
    "def cut(doc):\n",
    "    content = list(jieba.cut(doc))\n",
    "    stopwords = get_stop_words()\n",
    "    return '/'.join([w for w in content if w not in stopwords and w!=' '])\n",
    "def handle_desc(desc):\n",
    "    desc = strQ2B(desc)\n",
    "    cut = jieba.cut(desc)\n",
    "    stopwords = get_stop_words()\n",
    "    return [w for w in cut if w not in stopwords and w!=' ']\n",
    "\n",
    "import pandas as pd\n",
    "def getredItem(city):\n",
    "    df = pd.read_csv(\"newdata/redhead.csv\",delimiter=\"$\",header=None)\n",
    "    df.columns = [\"地市\",\"红头文件描述\"]\n",
    "    res = df[df[\"地市\"]==city][\"红头文件描述\"].tolist()\n",
    "    print(res)\n",
    "    return res[0]\n",
    "getredItem(\"山东省\")\n",
    "\n",
    "def getResult(topic_num,test_file=\"newdata/input.csv\"):\n",
    "    res_dict = {}\n",
    "    with open('newdata/dict_save', 'rb') as f:\n",
    "        load_dictionary = pickle.load(f)   # read file and build object\n",
    "    with open('newdata/labelestimeter', 'rb') as f:\n",
    "        le = pickle.load(f)   # read file and build object\n",
    "    from gensim import models\n",
    "    load_lda = models.ldamodel.LdaModel.load('newdata/lda.model')\n",
    "\n",
    "    model = load_model('newdata/my_model.h5')\n",
    "    model.load_weights('newdata/my_model_weights.h5')\n",
    "    \n",
    "    a = load_dictionary.doc2bow(handle_desc(desc))\n",
    "    topic_distribute = load_lda[a]\n",
    "#     print(topic_distribute)\n",
    "    x_test = np.zeros((topic_num,))\n",
    "    for tupl in topic_distribute:\n",
    "#         print(tupl)\n",
    "        x_test[tupl[0]]=tupl[1]\n",
    "    res = model.predict(x_test.reshape(1,topic_num))\n",
    "    res_dict[\"label\"] = le.inverse_transform([np.argmax(res[0])])[0]\n",
    "    res_dict[\"经营范围\"] = desc\n",
    "    res_dict[\"所属城市\"] = alldf[\"所在城市\"][0]\n",
    "    print(alldf[\"所在城市\"][0])\n",
    "    res_dict[\"公司名称\"] = corpName\n",
    "    res_dict[\"红头文件描述项目\"] = getredItem(alldf[\"所在城市\"][0])\n",
    "    \n",
    "    return res_dict\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    topic_num = 25\n",
    "    corpName = \"济南二机床集团有限公司技术中心\"  # tableau点击选中的企业名\n",
    "    resdict = getResult(corpName,topic_num)\n",
    "    print(resdict)\n",
    "    resdf = pd.DataFrame({\"label\":[resdict[\"label\"]],\n",
    "                 \"经营范围\":[resdict[\"经营范围\"]],\n",
    "                 \"所属城市\":[resdict[\"所属城市\"]],\n",
    "                 \"公司名称\":[resdict[\"公司名称\"]],\n",
    "                 \"红头文件描述项目\":[resdict[\"红头文件描述项目\"]]})\n",
    "    resdf.to_csv(\"newdata/output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
