{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1 HMM概率计算问题\n",
    "已知模型$\\lambda$的所有参数和观测序列$O$, 计算该模型下出现该观测序列的概率$P\\left( O|\\lambda  \\right) $  \n",
    "\n",
    "### 一. 理论可行. 实际不行的方法 - 直接计算\n",
    "1. 方法 :  \n",
    " 列举所有可能的长度为$T$的状态序列$I=\\left\\{ { i }_{ 1 },{ i }_{ 2 }...{ i }_{ T } \\right\\} $, 对比所有这些可能的状态序列和观测序列$O$, 获得联合概率$P\\left( O,I|\\lambda  \\right) $. 最后对所有这些状态序列对应的联合概率求和, 得到$P\\left( O|\\lambda  \\right) $  \n",
    "2. 为什么实际不可行  \n",
    " 列举所有可能的状态序列的过程 , 相当于构建了一个完全N叉数. 一个$T$层完全N叉树, 叶子节点个数会达到$N^T$, 加上根节点有$N$中选择, 所以状态序列共有$N^T$种. 指数增长导致无法一一列举\n",
    " \n",
    "### 二. 前向算法\n",
    "1. 前向算法是一种动态规划算法, 从局部最优解递推到全局最优解\n",
    "2. 何为前向概率  \n",
    " 1. 给定HMM模型$\\lambda$, 则到时刻$t$ 为止, 观测序列为${ o }_{ 1 },{ o }_{ 2 }...{ o }_{ t }$, 且时刻t的状态为$q_i$的概率, 称为前向概率. 计做$${ \\alpha  }_{ t }\\left( i \\right) =P\\left( { o }_{ 1 },{ o }_{ 2 }...{ o }_{ t },{ i }_{ t }={ q }_{ i }|\\lambda  \\right) $$  \n",
    " 2. 因为每个时刻, 都有$i\\in [1,2..N]$共$N$种可能的状态. 因此每个时刻都有$N$个前向概率\n",
    "3. 求观测序列概率的前向算法步骤  \n",
    "  1. 初始值  \n",
    "   ${ \\alpha  }_{ 1 }\\left( i \\right) ={ \\pi  }_{ i }{ b }_{ i }\\left( { o }_{ 1 } \\right) ,\\quad i=1,2..N,{ o }_{ 1 }$观测值已知  \n",
    "  2. 递推    \n",
    "   ${ { \\alpha  } }_{ t+1 }\\left( i \\right) =\\sum _{  }^{  }{ \\left[ { \\alpha  }_{ t }\\left( j \\right) *{ a }_{ ji } \\right]  } *{ b }_{ i }\\left( { o }_{ t+1 } \\right) $  \n",
    "  3. 终止  \n",
    "   $$P\\left( O|\\lambda  \\right) =\\sum _{ i=1 }^{ N }{ { \\alpha  }_{ T }\\left( i \\right)  } \\\\    \n",
    "   \\because \\sum _{ i=1 }^{ N }{ { \\alpha  }_{ T }\\left( i \\right)  } =P\\left( { o }_{ 1 },{ o }_{ 2 }...{ o }_{ t },{ i }_{ t }={ q }_{ 1 }|\\lambda  \\right) +P\\left( { o }_{ 1 },{ o }_{ 2 }...{ o }_{ t },{ i }_{ t }={ q }_{ 2 }|\\lambda  \\right) +..+P\\left( { o }_{ 1 },{ o }_{ 2 }...{ o }_{ t },{ i }_{ t }={ q }_{ N }|\\lambda  \\right) =P\\left( { o }_{ 1 },{ o }_{ 2 }...{ o }_{ t }|\\lambda  \\right) $$\n",
    "   \n",
    "4. 前向计算观测序列图解\n",
    "<img src='img/forward_HMM' height='50%' width='50%'>\n",
    "\n",
    "5. 前向模型计算案例  \n",
    "第一节的盒子球模型$\\lambda =\\left( A,B,\\pi  \\right) $. 状态集合$Q=\\left\\{ 1,2,3 \\right\\} $, 观测集合$ V=\\left\\{  红,白\\right\\} $  \n",
    " $A=\\begin{bmatrix} 0.5 & 0.2 & 0.3 \\\\ 0.3 & 0.5 & 0.2 \\\\ 0.2 & 0.3 & 0.5 \\end{bmatrix},\\quad B=\\begin{bmatrix} 0.5 & 0.5 \\\\ 0.4 & 0.6 \\\\ 0.7 & 0.3 \\end{bmatrix},\\quad \\pi ={ \\left[ 0.2,0.4,0.4 \\right]  }^{ T }$, 观测结果为$O=\\left\\{ 红,白,红 \\right\\} $  \n",
    "( 1 ) 计算初值  \n",
    "  ${ \\alpha  }_{ 1 }\\left( 1 \\right) ={ \\pi  }_{ 1 }*{ b }_{ 1 }\\left( { o }_{ 1 } \\right) =0.2*0.5=0.1\\\\ { \\alpha  }_{ 1 }\\left( 2 \\right) ={ \\pi  }_{ 2 }*{ b }_{ 2 }\\left( { o }_{ 1 } \\right) =0.4*0.4=0.16\\\\ { \\alpha  }_{ 1 }\\left( 3 \\right) ={ \\pi  }_{ 3 }*{ b }_{ 3 }\\left( { o }_{ 1 } \\right) =0.4*0.7=0.28$  \n",
    "( 2 ) 递推  \n",
    "${ \\alpha  }_{ 2 }\\left( 1 \\right) =\\sum _{  }^{  }{ \\left[ { \\alpha  }_{ 1 }\\left( j \\right) *{ a }_{ j1 } \\right]  } *{ b }_{ 1 }\\left( { o }_{ 2 } \\right) =(0.1*0.5+0.16*0.3+0.28*0.2)*0.5=0.154*0.5=0.077\\\\ { \\alpha  }_{ 2 }\\left( 2 \\right) =\\sum _{  }^{  }{ \\left[ { \\alpha  }_{ 1 }\\left( j \\right) *{ a }_{ j2 } \\right]  } *{ b }_{ 2 }\\left( { o }_{ 2 } \\right) =(0.1*0.2+0.16*0.5+0.28*0.3)*0.6=0.184*0.6=0.1104\\\\ { \\alpha  }_{ 2 }\\left( 3 \\right) =\\sum _{  }^{  }{ \\left[ { \\alpha  }_{ 1 }\\left( j \\right) *{ a }_{ j3 } \\right]  } *{ b }_{ 3 }\\left( { o }_{ 2 } \\right) =0.0606\\\\ \\\\ { \\alpha  }_{ 3 }\\left( 1 \\right) =\\sum _{  }^{  }{ \\left[ { \\alpha  }_{ 2 }\\left( j \\right) *{ a }_{ j1 } \\right]  } *{ b }_{ 1 }\\left( { o }_{ 3 } \\right) =0.04187\\\\ { \\alpha  }_{ 3 }\\left( 2 \\right) =\\sum _{  }^{  }{ \\left[ { \\alpha  }_{ 2 }\\left( j \\right) *{ a }_{ j1 } \\right]  } *{ b }_{ 2 }\\left( { o }_{ 3 } \\right) =0.03551\\\\ { \\alpha  }_{ 3 }\\left( 3 \\right) =\\sum _{  }^{  }{ \\left[ { \\alpha  }_{ 2 }\\left( j \\right) *{ a }_{ j1 } \\right]  } *{ b }_{ 3 }\\left( { o }_{ 3 } \\right) =0.05284\\\\ \\therefore \\quad P\\left( O|\\lambda  \\right) =0.04187+0.03551+0.05284=0.13022$\n",
    "  \n",
    " \n",
    "### 三. 后向算法\n",
    "1. 后向概率的定义  \n",
    " 给定HMM模型$\\lambda$, 在$t$时刻状态为$q_i$的条件下, 从时刻$t+1$到$T$的观测序列为$\\left\\{  o_{t+1},o_{t+2}..o_{T} \\right\\}$的概率为后向概率  \n",
    "2. 观测序列的后向算法  \n",
    "  1. 初始化  \n",
    "   对最终时刻的所有隐藏状态$q_i$, 规定其后向概率${ \\beta  }_{ T }\\left( i \\right) =1$, 其中$i\\in \\left[ 1,2..N \\right] $  \n",
    "  2. 递推  \n",
    "   ${ \\beta  }_{ t }\\left( i \\right) =\\sum _{ j=1 }^{ N }{ \\left[ { a }_{ ij }{ b }_{ j }\\left( { o }_{ t+1 } \\right) { \\beta  }_{ t+1 }\\left( j \\right)  \\right]  } $  \n",
    "  3. 终止, 得到观测序列概率  \n",
    "   $P\\left( O|\\lambda  \\right) =\\sum _{ i=1 }^{ N }{ \\left[ { \\pi  }_{ i }{ b }_{ i }\\left( { o }_{ 1 } \\right) { \\beta  }_{ 1 }\\left( i \\right)  \\right]  } $  \n",
    "3. 后向算法图解\n",
    "<img src='img/backwardhmm.png' height='45%' width='45%'>\n",
    "\n",
    "### 四. 前向后向概率综合应用  \n",
    "1. 前向后向联合概率  \n",
    " 若同时满足前向, 后向概率, 则有$t$时刻状态$q_i$, 且$t$时刻之前观测序列为$\\left\\{ { o }_{ 1 },{ o }_{ 2 }..{ o }_{ t-1 } \\right\\} $, t时刻之后观测序列为$\\left\\{ { o }_{ t+1 },{ o }_{ t+2 }..{ o }_{ T } \\right\\} $的概率为${ \\alpha  }_{ t }\\left( i \\right) { \\beta  }_{ t }\\left( i \\right) $ ,即$${ \\alpha  }_{ t }\\left( i \\right) { \\beta  }_{ t }\\left( i \\right) =P\\left( { o }_{ 1 },{ o }_{ 2 }..{ o }_{ t },{ i }_{ t }={ q }_{ i } \\right) *P\\left( { o }_{ t+1 },{ o }_{ t+2 }..{ o }_{ T }|{ i }_{ t }={ q }_{ i } \\right) =P\\left( { o }_{ t+1 },{ o }_{ t+2 }..{ o }_{ T }|{ o }_{ 1 },{ o }_{ 2 }..{ o }_{ t },{ i }_{ t }={ q }_{ i } \\right) =P\\left( O,{ i }_{ t }={ q }_{ i } \\right) $$ \n",
    "2. 前向后向联合概率产生的计算场景  \n",
    "  1. 给定HMM模型参数和观测序列$O$, 则在$t$时刻处于状态$q_i$的概率 :  $${ \\gamma  }_{ t }\\left( i \\right) =P\\left( { i }_{ t }={ q }_{ i }|O \\right) =\\frac { P\\left( { i }_{ t }={ q }_{ i },O \\right)  }{ \\sum _{ j=1 }^{ N }{ P\\left( { i }_{ t }={ q }_{ j },O \\right)  }  } =\\frac { { \\alpha  }_{ t }\\left( i \\right) { \\beta  }_{ t }\\left( i \\right)  }{ \\sum _{ j=1 }^{ N }{ { \\alpha  }_{ t }\\left( j \\right) { \\beta  }_{ t }\\left( j \\right)  }  } $$  \n",
    "  2. 给定HMM模型参数和观测序列$O$, 则$t$时刻处于状态$q_i$且$t+1$时刻处于状态$q_j$的概率$${ \\xi  }_{ t }\\left( i,j \\right) =P\\left( { i }_{ t }={ q }_{ i },{ i }_{ t+1 }={ q }_{ j }|O \\right) =\\frac { P\\left( { i }_{ t }={ q }_{ i },{ i }_{ t+1 }={ q }_{ j },O \\right)  }{ \\sum _{ i=1 }^{ N }{ \\sum _{ j=1 }^{ N }{ P\\left( { i }_{ t }={ q }_{ i },{ i }_{ t+1 }={ q }_{ j },O \\right)  }  }  } \\\\ \\because P\\left( { i }_{ t }={ q }_{ i },{ i }_{ t+1 }={ q }_{ j },O \\right) ={ \\alpha  }_{ t }\\left( i \\right) { a }_{ i,j }{ b }_{ j }\\left( { o }_{ t+1 } \\right) { \\beta  }_{ t+1 }\\left( j \\right) \\quad \\quad \\therefore { \\xi  }_{ t }\\left( i,j \\right) =\\frac { { \\alpha  }_{ t }\\left( i \\right) { a }_{ i,j }{ b }_{ j }\\left( { o }_{ t+1 } \\right) { \\beta  }_{ t+1 }\\left( j \\right)  }{ \\sum _{ i=1 }^{ N }{ \\sum _{ j=1 }^{ N }{ { \\alpha  }_{ t }\\left( i \\right) { a }_{ i,j }{ b }_{ j }\\left( { o }_{ t+1 } \\right) { \\beta  }_{ t+1 }\\left( j \\right)  }  }  } $$\n",
    "3. 应用${ \\gamma  }_{ t }\\left( i \\right) $与${ \\xi  }_{ t }\\left( i,j \\right) $的计算  \n",
    "  1. 观测序列$O$下状态$q_i$出现的期望$$\\sum _{ t=1 }^{ T }{ { \\gamma  }_{ t }\\left( i \\right)  } $$ \n",
    "  2. 观测序列$O$下由状态$q_i$转移的期望$$\\sum _{ t=1 }^{ T-1 }{ { \\gamma  }_{ t }\\left( i \\right)  } $$\n",
    "  3.  观测序列$O$下由状态$q_i$转移成$q_j$的期望$$\\sum _{ t=1 }^{ T-1 }{ { \\xi  }_{ t }\\left( i,j \\right)  } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2 学习算法\n",
    "\n",
    "HMM模型参数学习, 分为两种形式. \n",
    "- 一种是训练数据同时包含观测序列$O$和对应的隐藏状态序列, 此时使用监督学习实现\n",
    "- 另一种是训练数据只有观测序列$O$, 此时只能通过EM算法实现\n",
    "\n",
    "### 一. 监督学习算法\n",
    "1. 场景  \n",
    " 训练数据中, 有$S$个长度相同的观测序列$O$和对应的状态序列$I$, 构成训练集$\\left\\{ \\left( { O }_{ 1 },{ I }_{ 1 } \\right) ,\\left( { O }_{ 2 },{ I }_{ 2 } \\right) ,..,\\left( { O }_{ S },{ I }_{ S } \\right)  \\right\\} $. 可用极大似然估计学习HMM参数  \n",
    "2. 参数学习方法  \n",
    "  1. 状态转移概率$a_{ij}$   \n",
    "   设样本集合中, 时刻$t$的状态$i$到时刻$t+1$时变成状态$j$的频数时$A_{ij}$, 则转移概率估计为  $$\\hat { { a }_{ ij } } =\\frac { { A }_{ ij } }{ \\sum _{ j=1 }^{ N }{ { A }_{ ij } }  } $$  \n",
    "  2. 观测概率${ b }_{ j }\\left( k \\right) $  \n",
    "   设样本集合中, 状态$j$时观测到结果$k$的频数是$B_{jk}$,可观测到的结果共有$M$种, 那么观测概率${ b }_{ j }\\left( k \\right) $为  $$\\hat { { b }_{ j }\\left( k \\right)  } =\\frac { { B }_{ jk } }{ \\sum _{ k=1 }^{ M }{ { B }_{ jk } }  } $$  \n",
    "  3. 初始状态$\\pi_i$的学习, 统计S个样本中初始状态为$q_i$的频数\n",
    "\n",
    "### 二. 非监督学习-Baum-Welch算法\n",
    "1. 场景  \n",
    " 训练数据中, 只有观测序列$O$而没有隐藏的状态序列$I$时, 使用EM来最大化概率模型  \n",
    "2. HMM模型, 实际上是一个含有隐变量的概率模型$$P\\left( O|\\lambda  \\right) =\\sum _{ I }^{  }{ P\\left( O,I|\\lambda  \\right)  } =\\sum _{ I }^{  }{ P\\left( O|I,\\lambda  \\right) *P\\left( I|\\lambda  \\right)  } $$它的参数可以用EM算法实现  \n",
    "3. EM实现步骤  \n",
    "  1. 确定完全数据的对数似然  \n",
    "   完全数据的对数似然函数$\\log { P\\left( O,I|\\lambda  \\right)  } $  \n",
    "  2. E步: 最大化期望函数  \n",
    "   这里的期望函数选择$Q$, 即$$Q\\left( \\lambda ,\\bar { \\lambda  }  \\right) =\\sum _{ I }^{  }{ log\\left[ P\\left( O,I|\\lambda  \\right)  \\right] *P\\left( O,I|\\bar { \\lambda  }  \\right)  } $$其中$\\lambda $为模型参数, $\\bar { \\lambda  } $为HMM模型当前的估计值, 且有观测序列和状态序列的联合概率$$P\\left( O,I|\\lambda  \\right) ={ \\pi  }_{ { i }_{ 1 } }{ b }_{ { i }_{ 1 } }\\left( { o }_{ 1 } \\right) *{ a }_{ { i }_{ 1 }{ i }_{ 2 } }{ b }_{ { i }_{ 2 } }\\left( { o }_{ 2 } \\right) *...*{ a }_{ { i }_{ T-1 }\\quad ,{ i }_{ T } }{ b }_{ { i }_{ T } }\\left( { o }_{ T } \\right) $$所以函数$Q$可写成$$Q\\left( \\lambda ,\\bar { \\lambda  }  \\right) =\\sum _{ I }^{  }{ \\left\\{ log\\left( { \\pi  }_{ { i }_{ 1 } } \\right) +\\sum _{ t=1 }^{ T-1 }{ log{ a }_{ { i }_{ t }{ i }_{ t+1 } } } +\\sum _{ t=1 }^{ t }{ log{ b }_{ { i }_{ t } }\\left( { o }_{ t } \\right)  }  \\right\\} *P\\left( O,I|\\bar { \\lambda  }  \\right)  } \\\\ \\quad \\quad \\quad \\quad \\quad =P\\left( O,I|\\bar { \\lambda  }  \\right) *\\sum _{ I }^{  }{ log\\left( { \\pi  }_{ { i }_{ 1 } } \\right)  } +P\\left( O,I|\\bar { \\lambda  }  \\right) *\\sum _{ I }^{  }{ \\sum _{ t=1 }^{ T-1 }{ log{ a }_{ { i }_{ t }{ i }_{ t+1 } } }  } +P\\left( O,I|\\bar { \\lambda  }  \\right) *\\sum _{ I }^{  }{ \\sum _{ t=1 }^{ t }{ log{ b }_{ { i }_{ t } }\\left( { o }_{ t } \\right)  }  } \\\\ \\\\ $$  \n",
    "  3. M步最大化函数$Q$的值  \n",
    "   因为要估计的三个参数都在函数Q的不同项里,所以可以分别估计$\\pi,a,b$  \n",
    "      1. $\\pi_i$的估计  \n",
    "       因为$\\pi_i$需要满足条件$\\sum _{ i=1 }^{ N }{ { \\pi  }_{ i } } =1$, 所以与$Q\\left( \\lambda ,\\bar { \\lambda  }  \\right) $的第一项一起构造拉格朗日函数$$P\\left( O,I|\\bar { \\lambda  }  \\right) *\\sum _{ I }^{  }{ log\\left( { \\pi  }_{ { i }_{ 1 } } \\right)  } +\\gamma \\left\\{ \\sum _{ i=1 }^{ N }{ { \\pi  }_{ i } } -1 \\right\\} \\xrightarrow [  ]{ \\quad 只考虑第一个时间的状态\\quad  } P\\left( O,{ i }_{ 1 }=i|\\bar { \\lambda  }  \\right) *\\sum _{ I }^{  }{ log\\left( { \\pi  }_{ { i }_{ 1 } } \\right)  } +\\gamma \\left\\{ \\sum _{ i=1 }^{ N }{ { \\pi  }_{ i } } -1 \\right\\} $$  \n",
    "       $\\therefore \\quad P\\left( O,{ i }_{ 1 }=i|\\bar { \\lambda  }  \\right) +\\gamma { \\pi  }_{ i }=0\\\\ \\quad 对i求和有P\\left( O|\\bar { \\lambda  }  \\right) +\\gamma =0,\\quad 即\\gamma =-P\\left( O|\\bar { \\lambda  }  \\right) ,\\quad 代入上式有$ $${ \\pi  }_{ i }=\\frac { P\\left( O,{ i }_{ 1 }=i|\\bar { \\lambda  }  \\right)  }{ P\\left( O|\\bar { \\lambda  }  \\right)  } $$   \n",
    "      2. $a_{ij}$的估计  \n",
    "      观察第二项, 可以写成\n",
    "      $$P\\left( O,I|\\bar { \\lambda  }  \\right) *\\sum _{ I }^{  }{ \\sum _{ t=1 }^{ T-1 }{ log{ a }_{ { i }_{ t }{ i }_{ t+1 } } }  } =P\\left( O,{ i }_{ t }=i,{ i }_{ t+1 }=j|\\bar { \\lambda  }  \\right) *\\sum _{ i=1 }^{ N }{ \\sum _{ j=1 }^{ N }{ \\sum _{ t=1 }^{ T-1 }{ log{ a }_{ { i }_{ t }j } }  }  } $$  \n",
    "      与附加条件$\\sum _{ j=1 }^{ N }{ { a }_{ ij } } =1$一起构造拉格朗日乘子, 得出$${ a }_{ ij }=\\frac { \\sum _{ t=1 }^{ T-1 }{ P\\left( O,{ i }_{ t }=i,{ i }_{ t+1 }=j|\\bar { \\lambda  }  \\right)  }  }{ \\sum _{ t=1 }^{ T-1 }{ P\\left( O,{ i }_{ t }=i|\\bar { \\lambda  }  \\right)  }  } $$\n",
    "      3. ${ b }_{ j }\\left( k \\right) $的估计 \n",
    "      Q函数第三项$$P\\left( O,I|\\bar { \\lambda  }  \\right) *\\sum _{ j=1 }^{ N }{ \\sum _{ t=1 }^{ t }{ log{ b }_{ j }\\left( { o }_{ t } \\right)  }  } =P\\left( O,{ i }_{ t }=j|\\bar { \\lambda  }  \\right) \\sum _{ j=1 }^{ N }{ \\sum _{ t=1 }^{ T }{ log{ b }_{ j }\\left( { o }_{ t } \\right)  }  } $$同样有附件条件$\\sum _{ k=1 }^{ M }{ { b }_{ j }\\left( k \\right)  } =1$, 构造拉格朗日乘子方程. 只有在${ o }_{ t }={ v }_{ k }$时, ${ b }_{ j }\\left( { o }_{ t } \\right)$对${ b }_{ j }\\left( k \\right) $的偏导才不等于0, 用$I(o_t=v_k)$表示, 求得$${ b }_{ j }\\left( k \\right) =\\frac { \\sum _{ t=1 }^{ T }{ \\left[ P\\left( O,{ i }_{ t }=j|\\bar { \\lambda  }  \\right) I\\left( { o }_{ t }={ v }_{ k } \\right)  \\right]  }  }{ \\sum _{ t=1 }^{ T }{ P\\left( O,{ i }_{ t }=j|\\bar { \\lambda  }  \\right)  }  } $$\n",
    "4. Baum-Welch参数估计公式  \n",
    " 利用前向后向概率的期望公式, 上一节已给出 :   \n",
    " 1. 给定HMM模型参数和观测序列$O$ , 则在$ t$ 时刻处于状态$ q_i$的概率为$\\gamma_t(i)$  \n",
    " 2. 给定HMM模型参数和观测序列 OO , 则$t $时刻处于状态$ q_i$且$t+1 $时刻处于状态$ q_j $的概率为${ \\xi  }_{ t }\\left( i,j \\right)$  \n",
    "所以参数估计公式可写成$${ a }_{ ij }=\\frac { \\sum _{ t=1 }^{ T-1 }{ { \\xi  }_{ t }\\left( i,j \\right)  }  }{ \\sum _{ t=1 }^{ T-1 }{ \\gamma _{ t }(i) }  } ,\\quad \\quad { b }_{ j }\\left( k \\right) =\\frac { \\sum _{ t=1,{ o }_{ t }={ v }_{ k } }^{ T }{ \\gamma _{ t }(j) }  }{ \\sum _{ t=1 }^{ T }{ \\gamma _{ t }(j) }  } ,\\quad \\quad { \\pi  }_{ i }=\\gamma _{ 1 }(i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.3 预测算法\n",
    "\n",
    "#### 一. 预测算法的概念 \n",
    "1. 预测算法是要解决, 给定模型HMM所有参数后, 确定在得到观测序列$O$后, 找到概率最大的状态序列$I$.\n",
    "2. 这个概率最大的状态序列$I$, 称为预测算法的最优路径. 最优路径有这个一个规律 :  \n",
    " 如果确定了某段时刻$t$到时刻$t+1$的最优路径, 则该最优路径必是整体有路径中该段时刻的最优路径.   \n",
    " 因此, 可以使用动态规划算法, 从局部最优解迭代得到整体最优解  \n",
    " \n",
    "#### 二. 维特比算法\n",
    "1. 符号说明  \n",
    "  1. 最优状态序列 : ${ I }^{ * }=\\left\\{ { i }_{ 1 }^{ * },{ i }_{ 2 }^{ * },..,{ i }_{ T }^{ * } \\right\\} $  \n",
    "  2. 定义最优路径在时刻$t$的状态为$i$, 且到时刻$t$为止,最优状态序列产生的概率为${ \\vartheta  }_{ t }\\left( i \\right) $, 则有表达式  \n",
    "   $ { \\vartheta  }_{ t }\\left( i \\right) =\\max _{ { i }_{ 1 },{ { i }_{ 2 } },..,{ i }_{ t-1 } }{ P\\left( { i }_{ t }=i,\\left\\{ { i }_{ 1 },{ { i }_{ 2 } },..,{ i }_{ t-1 } \\right\\} ,\\left\\{ { o }_{ 1 },{ { o }_{ 2 } },..,{ o }_{ t } \\right\\} |\\lambda  \\right)  } ,\\quad i=1,2,..,N\\\\ { \\vartheta  }_{ t+1 }\\left( i \\right) =\\max _{ { i }_{ 1 },{ { i }_{ 2 } },..,{ i }_{ t-1 } }{ P\\left( { i }_{ t+1 }=i,\\left\\{ { i }_{ 1 },{ { i }_{ 2 } },..,{ i }_{ t } \\right\\} ,\\left\\{ { o }_{ 1 },{ { o }_{ 2 } },..,{ o }_{ t+1 } \\right\\} |\\lambda  \\right)  } \\\\ \\quad \\quad =\\max _{ 1\\le j\\le N }{ \\left\\{ { \\vartheta  }_{ t }\\left( j \\right) *{ a }_{ ji } \\right\\}  } *{ b }_{ i }\\left( { o }_{ t+1 } \\right)  $  \n",
    "  3. 定义最优路径在时刻$t$的状态为i,即该状态节点为  \n",
    "   ${ \\psi  }_{ t }\\left( i \\right) =\\underset { 1\\le j\\le N }{ argmax } \\left\\{ { \\vartheta  }_{ t-1 }\\left( j \\right) *{ a }_{ ji } \\right\\} $\n",
    "   \n",
    "2. 维特比算法过程  \n",
    "输入 : 模型$\\lambda$和观测序列$O$; 输出 : 最优路径$I^*$  \n",
    "  1. 初始化  \n",
    "   $$\\begin{cases} { \\vartheta  }_{ 1 }\\left( i \\right) ={ \\pi  }_{ i }{ b }_{ i }\\left( { o }_{ 1 } \\right)  \\\\ { \\psi  }_{ 1 }\\left( i \\right) =0 \\end{cases}$$  \n",
    "  2. 递推  \n",
    "  $$\\begin{cases} { \\vartheta  }_{ t }\\left( i \\right) =\\max _{ 1\\le j\\le N }{ \\left\\{ { \\vartheta  }_{ t-1 }\\left( j \\right) *{ a }_{ ji } \\right\\}  } *{ b }_{ i }\\left( { o }_{ t } \\right)  \\\\ { \\psi  }_{ t }\\left( i \\right) =\\underset { 1\\le j\\le N }{ argmax } \\left\\{ { \\vartheta  }_{ t-1 }\\left( j \\right) *{ a }_{ ji } \\right\\}  \\end{cases}$$  \n",
    "  3. 终止  \n",
    "   $$\\begin{cases} { P }^{ * }=\\max _{ 1\\le i\\le N }{ { \\vartheta  }_{ T }\\left( i \\right)  }  \\\\ { { i }_{ t } }^{ * }=\\underset { 1\\le j\\le N }{ argmax } \\left\\{ { \\vartheta  }_{ T }\\left( j \\right)  \\right\\}  \\end{cases}$$  \n",
    "  4. 回溯  \n",
    "  上一步终止后, 求得的$i^*_t$为最优路径上最后一时刻达到的状态, 根据这个状态回溯其对应$t-1,t-2,..,1$时刻的最优路径\n",
    "  \n",
    "#### 三. 维比特算法例子\n",
    "1. 已知$A=\\begin{bmatrix} 0.5 & 0.2 & 0.3 \\\\ 0.3 & 0.5 & 0.2 \\\\ 0.2 & 0.3 & 0.5 \\end{bmatrix},\\quad B=\\begin{bmatrix} 0.5 & 0.5 \\\\ 0.4 & 0.6 \\\\ 0.7 & 0.3 \\end{bmatrix},\\quad \\pi ={ \\left[ 0.2,0.4,0.4 \\right]  }^{ T }$, 观测结果为$O=\\left\\{ 红,白,红 \\right\\} $, 求其对应的观测序列\n",
    "2. 求解  \n",
    "  1. 初始化, t=1时 $${ \\vartheta  }_{ 1 }\\left( 1 \\right) ={ \\pi  }_{ 1 }{ b }_{ 1 }\\left( { o }_{ 1 } \\right) =0.2*0.5=0.1\\quad ,\\quad { \\vartheta  }_{ 1 }\\left( 2 \\right) ={ \\pi  }_{ 2 }{ b }_{ 2 }\\left( { o }_{ 1 } \\right) =0.4*0.4=0.16\\quad ,\\quad { \\vartheta  }_{ 1 }\\left( 3 \\right) ={ \\pi  }_{ 3 }{ b }_{ 3 }\\left( { o }_{ 1 } \\right) =0.4*0.7=0.28$$\n",
    "  2. t=2时, 计算3个状态的最优局部路径  \n",
    "  ${ \\vartheta  }_{ 2 }\\left( 1 \\right) =\\max _{ 1\\le j\\le 3 }{ \\left\\{ { \\vartheta  }_{ 1 }\\left( j \\right) *{ a }_{ j1 } \\right\\}  } *{ b }_{ 1 }\\left( { o }_{ 2 } \\right) \\\\ \\quad =\\max _{ 1 }{ \\left\\{ 0.1*0.5,0.16*0.3,0.28*0.2 \\right\\}  } *0.5\\\\ \\quad =0.028\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad ,\\quad { \\psi  }_{ 2 }\\left( 1 \\right) =3\\\\ { \\vartheta  }_{ 2 }\\left( 2 \\right) =\\max _{ 1\\le j\\le 3 }{ \\left\\{ { \\vartheta  }_{ 1 }\\left( j \\right) *{ a }_{ j2 } \\right\\}  } *{ b }_{ 2 }\\left( { o }_{ 2 } \\right) =0.0504\\quad \\quad \\quad \\quad \\quad ,\\quad { \\psi  }_{ 2 }\\left( 2 \\right) =3\\\\ { \\vartheta  }_{ 2 }\\left( 3 \\right) =\\max _{ 1\\le j\\le 3 }{ \\left\\{ { \\vartheta  }_{ 1 }\\left( j \\right) *{ a }_{ j3 } \\right\\}  } *{ b }_{ 3 }\\left( { o }_{ 2 } \\right) =0.0402\\quad \\quad \\quad \\quad \\quad ,\\quad { \\psi  }_{ 2 }\\left( 3 \\right) =3$  \n",
    "  3. t=3时, 计算3个状态的最优局部路径  \n",
    "   ${ \\vartheta  }_{ 3 }\\left( 1 \\right) =\\max _{ 1\\le j\\le 3 }{ \\left\\{ { \\vartheta  }_{ 2 }\\left( j \\right) *{ a }_{ j1 } \\right\\}  } *{ b }_{ 1 }\\left( { o }_{ 3 } \\right) =0.00756\\quad \\quad \\quad \\quad \\quad ,\\quad { \\psi  }_{ 2 }\\left( 1 \\right) =2\\\\ { \\vartheta  }_{ 3 }\\left( 2 \\right) =\\max _{ 1\\le j\\le 3 }{ \\left\\{ { \\vartheta  }_{ 2 }\\left( j \\right) *{ a }_{ j2 } \\right\\}  } *{ b }_{ 2 }\\left( { o }_{ 3 } \\right) =0.01008\\quad \\quad \\quad \\quad \\quad ,\\quad { \\psi  }_{ 2 }\\left( 2 \\right) =2\\\\ { \\vartheta  }_{ 3 }\\left( 3 \\right) =\\max _{ 1\\le j\\le 3 }{ \\left\\{ { \\vartheta  }_{ 2 }\\left( j \\right) *{ a }_{ j3 } \\right\\}  } *{ b }_{ 3 }\\left( { o }_{ 3 } \\right) =0.0147\\quad \\quad \\quad \\quad \\quad \\quad ,\\quad { \\psi  }_{ 2 }\\left( 3 \\right) =3$  \n",
    "  4. 回溯  \n",
    "  t=3时, 最优路径节点为${ { i }_{ 3 } }^{ * }=3$, 回溯达到该状态的t-1时刻状态为3, t-2时刻状态为3\n",
    "  所以, 最佳观测序列${ I }^{ * }=\\left\\{ 3,3,3 \\right\\} $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
