{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1 HMM模型基本概念\n",
    "\n",
    "#### 一. HMM模型定义\n",
    "1. HMM定义   \n",
    " HMM是一种时序模型, HMM认为时序的观测结果, 背后隐藏着一个不可观测的状态序列. 状态导致观测结果的产生(一个状态对应一个观测状态集的分布), 状态之间的转换遵循马尔科夫状态转移矩阵  \n",
    "  1. 状态序列 : state sequence\n",
    "  2. 观测序列 : observation sequence\n",
    "  \n",
    "#### 二. 符号定义\n",
    "1. 状态数 : $N$, 观测结果数 : $M$, 序列长度 : $T$\n",
    "1. 所有可能状态集合 : $Q=\\{q_1,q_2,q_3 .. q_N\\}$    \n",
    " 所有可能的观测值集合 : $V=\\{v_1,v_2,v_3 .. v_M\\}$\n",
    "3. 状态序列 : $I$   \n",
    " 观测序列 : $O$  \n",
    "4. 状态转移矩阵 : $A$  \n",
    " $A={[a_{ij}]}_{N*N}$ , 其中 $a_{ij}$=$p\\left( { i }_{ t+1 }={ q }_{ j }|{ i }_{ t }={ q }_{ i } \\right) $  \n",
    "5. 观测矩阵 : $B$  \n",
    " $B=[{ b }_{ j }(k)]_{N*M}$ , 其中 ${ b }_{ j }(k)=P\\left( { o }_{ t }={ v }_{ k }|{ i }_{ t }={ q }_{ j } \\right) $  \n",
    " 即时刻$t$ 处于状态${ q }_{ j }$时, 观测结果为${ v }_{ k }$的概率  \n",
    "6. 初始状态$\\pi$  \n",
    " ${ \\pi  }_{ i }=P\\left( { i }_{ t }={ q }_{ i } \\right) $\n",
    " \n",
    "#### 三. HMM模型表示 \n",
    "HMM模型需要三个参数建模 : 初始状态矩阵, 状态转移矩阵A, 观测结果和状态的对应矩阵B.   \n",
    " 因此, 隐马尔科夫模型$\\lambda =\\left\\{ \\pi ,A,B \\right\\} $  \n",
    "1. 初始状态矩阵$\\pi$和状态转移矩阵$A$, 决定状态序列$I$\n",
    "2. 潜在的状态序列$I$和观测矩阵$B$, 决定了观测序列$O$\n",
    "\n",
    "#### 四. HMM模型的两个假设\n",
    "1. 齐次马尔科夫 : 即 $t+1$时刻的状态只依赖于 $t$ 时刻的状态  \n",
    "2. 观测独立性 : 即 $t$ 时刻的观测值只和 $t$ 时刻的状态的状态\n",
    "\n",
    "#### 五. 盒子和球模型\n",
    "1. 文字描述 :   \n",
    " 有4个盒子编号1,2,3,4. 每个盒子里都装有2种颜色的球: 红球和白球 . 4个盒子中, 红白球的个数分别为:  \n",
    "      1. 1号盒子5:5  \n",
    "      2. 2号盒子3:7  \n",
    "      3. 3号盒子6:4  \n",
    "      4. 4号盒子8:2.   \n",
    "      \n",
    " 首先, 从4个盒子中等概率随机选取一个盒子, 从该盒子中抽出一个球, 记录颜色后放回 , 然后去下一个盒子中抽取球. 规则是  \n",
    "      1. 如果当前是盒子1 , 则下一个盒子一定是盒子2 ;   \n",
    "      2. 如果当前盒子是2或3 , 则分别以0.4和0.6的概率转移到左边或右边的盒子;  \n",
    "      3. 如果当前是盒子4 , 则各以0.5的概率停留在盒子4或转移到盒子3;     \n",
    "      \n",
    " 如此选择盒子并抽取小球后, 得到观测序列$O=\\left\\{ 红, 红,白,白,红 \\right\\} $. 用HMM模型描述\n",
    " \n",
    "2. HMM模型描述\n",
    "  1. 状态集合 : $Q=\\left\\{  盒子1,盒子2,盒子3,盒子4  \\right\\} $  , $N=4$   \n",
    "   观测集合 : $V=\\left\\{ 红,白 \\right\\} $ , $M=2$  \n",
    "  2. 初始状态  \n",
    "   $\\pi =\\left\\{ 0.25,0.25,0.25,0.25 \\right\\} $\n",
    "  3. 状态转移矩阵  \n",
    "   $A=\\begin{bmatrix} 0 & 1 & 0 & 0 \\\\ 0.4 & 0 & 0.6 & 0 \\\\ 0 & 0.4 & 0 & 0.6 \\\\ 0 & 0 & 0.5 & 0.5 \\end{bmatrix}$   \n",
    " 4. 观测矩阵  \n",
    "  $B=\\begin{bmatrix} 0.5 & 0.5 \\\\ 0.3 & 0.7 \\\\ 0.6 & 0.4 \\\\ 0.8 & 0.2 \\end{bmatrix}$\n",
    "  \n",
    "#### 六. HMM观测序列产生过程\n",
    "初始条件下: $t=1$ , 初始状态分布 $\\pi $ 产生状态 $i_1$  \n",
    "1. 由状态$i_t$ 的观测概率分布$b_{i_t}(k)$ 生成观测值 $o_t$  \n",
    "2. 由状态$i_t$ 的状态转移概率分布 $a_{i_t,i_{t+1}}$生成状态$i_{t+1}$\n",
    "3. $t=t+1$ 转到第一步\n",
    "\n",
    "#### 七. HMM模型解决的三个问题  \n",
    "1. 概率计算 : 已知模型$\\lambda$的所有参数和观测序列$O$, 计算该模型下出现该观测序列的概率$P\\left( O|\\lambda  \\right) $  \n",
    "2. 学习问题 : 已知观测序列$O$ , 求模型$\\lambda$的所有参数 , 使得该模型下出现该观测序列的概率$P\\left( O|\\lambda  \\right) $最大  \n",
    "3. 预测问题 : 已知模型$\\lambda$的所有参数和观测序列$O$, 求该观测序列下最可能对应的状态序列是什么"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 动态规划思想\n",
    "\n",
    "#### 一. 动态规划概念\n",
    "1. 动态规划利用自底向上的的递推方式, 比递归算法在时间和空间上更优化.  \n",
    " 动态规划的构思方法和递归程序一样, 都是先从最接近结果的情形, 考虑递归的最后一步, 然后思考一个递归基.  \n",
    " 不同的是,编程实现时递归是从高层向底层实现, 而动态规划是从递归基开始向上实现 \n",
    "2. 动态规划3要素  \n",
    " 动态规划有3个核心元素  \n",
    "  1. 最优化子结构\n",
    "  2. 边界  \n",
    "  3. 状态转移方程\n",
    "2. 例子  \n",
    " 有一个10级台阶, 每次只能上1阶梯或2阶梯. 问上到第十级有多少种走法  \n",
    " 思路:  \n",
    "  1. 上到10级台阶的最后一步有两种可能: 一种是从9级上1级, 一种是从8级上2级.因此, 如果得知了上到9级的方法数量和上到8级的方法数量, 二者相加就是上到10级的全部方法数量. 所以有$f\\left( n \\right) =f\\left( n-1 \\right) +f\\left( n-2 \\right) $  \n",
    "  2. 边界 : 第1级只有一种方法, 第二级有两种方法(直接上两级/上两次1级). 即$f\\left( 1 \\right) =1,f\\left( 2 \\right) =2$\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共 89 种方法\n"
     ]
    }
   ],
   "source": [
    "def getMethodnumber():\n",
    "    a = 1\n",
    "    b = 2\n",
    "    for i in range(3,11):\n",
    "        c = a + b\n",
    "        a = b\n",
    "        b = c\n",
    "    return c\n",
    "print '一共',getMethodnumber(),'种方法'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二. 挖金矿\n",
    "1. 问题描述  \n",
    " 有5座金矿, 每座金矿的黄金储备量不同, 所需要的挖掘工人也不同. 若一共有10个人, 问如何分配者10个人, 才能使一次挖掘到的黄金总量最大\n",
    "<img src='img/dp_golden.png' height='60%' width='60%'/>\n",
    "2. 场景分析 \n",
    "  1. 最优子结构 - 从最接近结果的情形开始  \n",
    "  因为一个金矿有2种方法, 要么挖要么不挖. 因此, 对于最后一个金矿-第5个金矿, 其最优子结构为$max\\{\"10个人只挖前四个金矿|第五个金矿不挖\", \"5个人挖前四个金矿|5个人挖第5个金矿\"\\}$  \n",
    "  2. 边界  \n",
    "  边界为只有一座金矿时, 若所剩工人数量>金矿所需人数, 则挖这个金矿; 否则, 无法挖这个金矿  \n",
    "  3. 状态转移方程式  \n",
    "   若用$w$表示工人数量, $n$表示金矿编号(从0开始), 金矿黄金数量设为$g$, 金矿所需人数设为$p$  \n",
    "   $f\\left( n,w \\right) =0,\\quad 当n=0,w<p[0]\\\\ f\\left( n,w \\right) =g[0],\\quad 当n=0,w>=p[0]\\\\ f\\left( n,w \\right) =f\\left( n-1,w \\right) ,\\quad 当n>0,w<p[n]\\\\ f\\left( n,w \\right) =max\\left\\{ f\\left( n-1,w \\right) ,f\\left( n-1,w-p[n] \\right) +g[n] \\right\\} ,\\quad 当w>p[n]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 HMM概率计算问题\n",
    "已知模型$\\lambda$的所有参数和观测序列$O$, 计算该模型下出现该观测序列的概率$P\\left( O|\\lambda  \\right) $  \n",
    "\n",
    "#### 一. 理论可行. 实际不行的方法 - 直接计算\n",
    "1. 方法 :  \n",
    " 列举所有可能的长度为$T$的状态序列$I=\\left\\{ { i }_{ 1 },{ i }_{ 2 }...{ i }_{ T } \\right\\} $, 对比所有这些可能的状态序列和观测序列$O$, 获得联合概率$P\\left( O,I|\\lambda  \\right) $. 最后对所有这些状态序列对应的联合概率求和, 得到$P\\left( O|\\lambda  \\right) $  \n",
    "2. 为什么实际不可行  \n",
    " 列举所有可能的状态序列的过程 , 相当于构建了一个完全N叉数. 一个$T$层完全N叉树, 叶子节点个数会达到$N^T$, 加上根节点有$N$中选择, 所以状态序列共有$N^T$种. 指数增长导致无法一一列举\n",
    " \n",
    "#### 二. 前向算法\n",
    "1. 前向算法是一种动态规划算法, 从局部最优解递推到全局最优解\n",
    "2. 何为前向概率  \n",
    " 1. 给定HMM模型$\\lambda$, 则到时刻$t$ 为止, 观测序列为${ o }_{ 1 },{ o }_{ 2 }...{ o }_{ t }$, 且时刻t的状态为$q_i$的概率, 称为前向概率. 计做$${ \\alpha  }_{ t }\\left( i \\right) =P\\left( { o }_{ 1 },{ o }_{ 2 }...{ o }_{ t },{ i }_{ t }={ q }_{ i }|\\lambda  \\right) $$  \n",
    " 2. 因为每个时刻, 都有$i\\in [1,2..N]$共$N$种可能的状态. 因此每个时刻都有$N$个前向概率\n",
    "3. 求观测序列概率的前向算法步骤  \n",
    "  1. 初始值  \n",
    "   ${ \\alpha  }_{ 1 }\\left( i \\right) ={ \\pi  }_{ i }{ b }_{ i }\\left( { o }_{ 1 } \\right) ,\\quad i=1,2..N,{ o }_{ 1 }$观测值已知  \n",
    "  2. 递推    \n",
    "   ${ { \\alpha  } }_{ t+1 }\\left( i \\right) =\\sum _{  }^{  }{ \\left[ { \\alpha  }_{ t }\\left( j \\right) *{ a }_{ ji } \\right]  } *{ b }_{ i }\\left( { o }_{ t+1 } \\right) $  \n",
    "  3. 终止  \n",
    "   $P\\left( O|\\lambda  \\right) =\\sum _{ i=1 }^{ N }{ { \\alpha  }_{ T }\\left( i \\right)  } $\n",
    "\n",
    "#### 三. 后向算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习问题 : 已知观测序列$O$ , 求模型$\\lambda$的所有参数 , 使得该模型下出现该观测序列的概率$P\\left( O|\\lambda  \\right) $最大  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测问题 : 已知模型$\\lambda$的所有参数和观测序列$O$, 求该观测序列下最可能对应的状态序列是什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
