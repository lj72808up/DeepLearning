{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings;warnings.filterwarnings('ignore')\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 神经网络的Hello World\n",
    "#### 一. Hello World\n",
    "1. 对MNIST数据集分类  \n",
    "  1. MNIST数据集 : 60000个手写字母的灰度图片 (28\\*28像素) + 10000个测试数据\n",
    "  2. 识别图片中的数字进行分类 : 0-9\n",
    "2. 编程步骤 :  \n",
    "  1. 定义神经网络结构  \n",
    "    1. 第一层: Dense层, 密集连接层 (也叫全连接层)\n",
    "    2. 第二层: 10路softmax层, 返回一个数组, 表示被分到10个数字的概率值\n",
    "  2. 编译步骤 : \n",
    "   为了让神经网络进行训练, 还要定义额外的3个编译步骤\n",
    "    1. loss function : 衡量神经网络表现的方法, 也是神经网络不断迭代的正确方向\n",
    "    2. optimizer : 神经网络训练的优化方法\n",
    "    3. Metrics to monitor during training and testing : 这里我们使用精确度度量 (被正确分类的数目)  \n",
    "  3. 数据预处理  \n",
    "    1. 输入数据的shape变成符合第一层神经网络输入的需求 : 28\\*28的像素展开成一列作为一个输入样本\n",
    "    2. 输入数据归一化 : 因为灰度值在0~255不方便训练, 所以归一化每个像素点为0~1的值\n",
    "  4. 输出数据向量化  \n",
    "    因为数据集中的输出标签为0~9的数字, 为了让输出满足softmax的向量化, 所以使用keras的to_categorical把输出进行独热编码变成向量\n",
    "  5. 训练模型  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (60000, 28, 28)\n",
      "labels:  [7 2 1 ... 4 5 6]\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.2026 - acc: 0.9403\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0899 - acc: 0.9744\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0662 - acc: 0.9811\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0533 - acc: 0.9858\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0402 - acc: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73ea5bdf10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 导入mnist数据集\n",
    "from keras.datasets import mnist\n",
    "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n",
    "print 'train shape: ',train_images.shape  # ndarray\n",
    "2. # 构建网络\n",
    "from keras import models\n",
    "from keras import layers\n",
    "network = models.Sequential()\n",
    "# input_shape : 输入张量的形状, (28*28,)表示1维度向量\n",
    "network.add(layers.Dense(512,activation='relu',input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10,activation='softmax'))\n",
    "# 3. 编译\n",
    "network.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "# 4. 数据预处理\n",
    "train_images = train_images.reshape((60000,28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype('float32')/255\n",
    "# 5. 向量化输出\n",
    "from keras import utils\n",
    "print 'labels: ',test_labels\n",
    "train_labels = utils.to_categorical(train_labels)\n",
    "test_labels = utils.to_categorical(test_labels)\n",
    "# 6. 训练模型\n",
    "network.fit(train_images,train_labels,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 41us/step\n",
      "('test_acc: ', 0.9785)\n"
     ]
    }
   ],
   "source": [
    "# 测试集表现\n",
    "test_loss,test_acc = network.evaluate(test_images,test_labels)\n",
    "print('test_acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Representation\n",
    "\n",
    "#### 一. 张量 Tensor\n",
    "1. Scalar - 0D张量\n",
    "2. Vector - 1D张量\n",
    "3. Matrix - 2D张量\n",
    "4. 3D张量和多维张量\n",
    "\n",
    "#### 二. Tensor的3个属性\n",
    "1. number of axes(rank) : 张量是几维的\n",
    "```python\n",
    "print x.ndim # 0\n",
    "print y.ndim # 1\n",
    "print z.ndim # 2\n",
    "print n3.ndim # 3\n",
    "```\n",
    "2. shape : 标量没有的shape为空 : ()\n",
    "\n",
    "3. datd type \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0d.shape:  ()\n",
      "1d.shape:  (4,)\n",
      "2d.shape:  (3, 5)\n",
      "3d.shape:  (2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# 标量 : 0D-tensor\n",
    "x = np.array(10)\n",
    "\n",
    "# 1D-tensor\n",
    "y = np.array([12,3,6,14])\n",
    "\n",
    "# 2D-tensor\n",
    "z = np.array([[5,78,2,34,0],\n",
    "             [6,79,3,35,1],\n",
    "             [7,89,4,36,2]])\n",
    "\n",
    "# 3D-tensor\n",
    "n3 = np.array([[[1,2,3],\n",
    "                        [2,3,3]],\n",
    "                      [[1,34,1],\n",
    "                        [3,5,6]]])\n",
    "\n",
    "print '0d.shape: ',x.shape\n",
    "print '1d.shape: ',y.shape\n",
    "print '2d.shape: ', z.shape\n",
    "print '3d.shape: ',n3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 三. 展示MNIST数据集中的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fce53f67210>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce53ff1f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit,cmap=plt.cm.binary) # cmap : colormap, 默认为空,表示输入数据为3Dtensor, RGB图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 四. 真实世界中数据张量的例子\n",
    "1. Vector data  \n",
    " 2D张量 (features)\n",
    "2. TimeSeries数据/序列数据  \n",
    " 3D张量 (samples, timestamps, features)\n",
    "3. Images  \n",
    " 4D张量 (samples, height,width,channels)\n",
    "4. Video  \n",
    " 5D张量 (samples,frames,height,width,channel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
