{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 准备红头文件匹配项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 处理文件所需要的共有方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_words():\n",
    "    '''停用词表'''\n",
    "    with open('data/stop_words_utf8.txt') as f:\n",
    "        content = f.readlines()\n",
    "        stopwords = [w.strip() for w in content]\n",
    "        return stopwords\n",
    "\n",
    "# 全角转换成半角\n",
    "def strQ2B(ustring):\n",
    "    '''全角转半角\n",
    "    ustring : 需要转换的字符串\n",
    "    '''\n",
    "    ss = ''\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # 全角空格直接转换\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全角字符（除空格）根据关系转化\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss = ss + rstring\n",
    "    return ss\n",
    "# 对corpus中每个文章分词后滤出停用词\n",
    "def cut(doc):\n",
    "    '''分词'''\n",
    "    content = list(jieba.cut(doc))\n",
    "    stopwords = get_stop_words()\n",
    "    return '/'.join([w for w in content if w not in stopwords and w!=' '])\n",
    "\n",
    "def handle_desc(desc):\n",
    "    '''对企业描述分词'''\n",
    "    desc = strQ2B(desc)\n",
    "    cut = jieba.cut(desc)\n",
    "    stopwords = get_stop_words()\n",
    "    return [w for w in cut if w not in stopwords and w!=' ']\n",
    "\n",
    "def getLDA(df,topic_num):\n",
    "    from gensim.models import LdaMulticore\n",
    "    from gensim.corpora import Dictionary\n",
    "    # gensim\n",
    "    dictionary = Dictionary(df[\"经营业务范围\"])\n",
    "    print(dictionary)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in df[\"经营业务范围\"]]\n",
    "    lda = LdaMulticore(corpus=corpus,  # LDA训练语料\n",
    "                   id2word=dictionary, # id到单词的映射表\n",
    "                   num_topics=topic_num)      # LDA主题数量 \n",
    "    return lda,corpus,dictionary\n",
    "\n",
    "def get_topic_distribute(lda,doc):\n",
    "    return lda[doc]\n",
    "\n",
    "def get_all_doc_topic(df):\n",
    "    lda_matrix = np.zeros((df[\"经营业务范围\"].shape[0],topic_num),dtype='float64')\n",
    "    for index,doc in enumerate(corpus):\n",
    "        topics = get_topic_distribute(lda,corpus[index])\n",
    "        for topic_tuple in topics:\n",
    "            lda_matrix[index,topic_tuple[0]] = topic_tuple[1]\n",
    "    return lda_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分词输入文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdf = pd.read_csv(\"newdata/input.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.605 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['信息产业' '医养健康' '文化产业' '旅游产业' '旧动能' '海洋经济' '现代农业' '现代金融' '能源原材料' '能源新材料'\n",
      " '高端化工' '高端装备制造']\n"
     ]
    }
   ],
   "source": [
    "inputdf[\"经营业务范围\"] = inputdf[\"经营业务范围\"].apply(cut)\n",
    "inputdf[\"经营业务范围\"] = inputdf[\"经营业务范围\"].apply(lambda x:x.split(\"/\"))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "inputdf[\"label\"] = le.fit_transform(inputdf[\"label\"])\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>企业名称</th>\n",
       "      <th>所在城市</th>\n",
       "      <th>经营业务范围</th>\n",
       "      <th>统一信用代码</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>济南二机床集团有限公司技术中心</td>\n",
       "      <td>山东省</td>\n",
       "      <td>[道路, 货物运输, 普通, 货运, 三类, 汽车, 维修, 车身, 清洁, 维护, 第一类...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>浪潮集团有限公司技术中心</td>\n",
       "      <td>山东省</td>\n",
       "      <td>[商用, 密码, 产品, 开发, 生产, 销售, 有效期限, 许可证, 为准, 计算机, 软...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>鲁南制药集团股份有限公司技术中心</td>\n",
       "      <td>山东省</td>\n",
       "      <td>[生产, 销售, 原料药, 包装, 物品, 依法, 须, 批准, 项目, 相关, 部门, 批...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>济南轻骑摩托车有限公司技术中心</td>\n",
       "      <td>山东省</td>\n",
       "      <td>[摩托车, 零配件, 设计, 开发, 生产, 销售, 摩托车, 技术咨询, 服务, 引进, ...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>万华化学集团股份有限公司技术中心</td>\n",
       "      <td>山东省</td>\n",
       "      <td>[安全, 生产, 许可证, 范围, 化学, 危险品, 生产, 许可证, 范围, 铁路, 专用...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label              企业名称 所在城市  \\\n",
       "0     11   济南二机床集团有限公司技术中心  山东省   \n",
       "1      0      浪潮集团有限公司技术中心  山东省   \n",
       "2      1  鲁南制药集团股份有限公司技术中心  山东省   \n",
       "3     11   济南轻骑摩托车有限公司技术中心  山东省   \n",
       "4     10  万华化学集团股份有限公司技术中心  山东省   \n",
       "\n",
       "                                              经营业务范围 统一信用代码  \n",
       "0  [道路, 货物运输, 普通, 货运, 三类, 汽车, 维修, 车身, 清洁, 维护, 第一类...      -  \n",
       "1  [商用, 密码, 产品, 开发, 生产, 销售, 有效期限, 许可证, 为准, 计算机, 软...      -  \n",
       "2  [生产, 销售, 原料药, 包装, 物品, 依法, 须, 批准, 项目, 相关, 部门, 批...      -  \n",
       "3  [摩托车, 零配件, 设计, 开发, 生产, 销售, 摩托车, 技术咨询, 服务, 引进, ...      -  \n",
       "4  [安全, 生产, 许可证, 范围, 化学, 危险品, 生产, 许可证, 范围, 铁路, 专用...      -  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(3107 unique tokens: ['GC2', '三类', '专用设备', '业务', '为准']...)\n",
      "[(0, 0.028253261), (15, 0.22203906), (21, 0.16987671), (22, 0.5739977)]\n",
      "1320\n"
     ]
    }
   ],
   "source": [
    "topic_num = 25\n",
    "lda,corpus,dictionary = getLDA(inputdf,topic_num)\n",
    "#lda.print_topics()\n",
    "print(get_topic_distribute(lda,corpus[0]))\n",
    "print(len(corpus))\n",
    "# 所有样本主题分布\n",
    "all_topic = get_all_doc_topic(inputdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03582705, 0.        , 0.        , ..., 0.57347691, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.29690465, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01333333, 0.01333333, 0.01333333, ..., 0.01333333, 0.01333333,\n",
       "        0.68000001]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1320, 25) (1320, 12)\n"
     ]
    }
   ],
   "source": [
    "x = all_topic\n",
    "y = pd.get_dummies(inputdf[\"label\"])\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03582705, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.21375732, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.17110544, 0.57347691, 0.        , 0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1320/1320 [==============================] - 0s 377us/step - loss: 0.9995 - acc: 0.8439\n",
      "Epoch 2/60\n",
      "1320/1320 [==============================] - 0s 307us/step - loss: 0.6097 - acc: 0.8765\n",
      "Epoch 3/60\n",
      "1320/1320 [==============================] - 0s 330us/step - loss: 0.6065 - acc: 0.8765\n",
      "Epoch 4/60\n",
      "1320/1320 [==============================] - 0s 330us/step - loss: 0.6250 - acc: 0.8765\n",
      "Epoch 5/60\n",
      "1320/1320 [==============================] - 0s 355us/step - loss: 0.6324 - acc: 0.8765\n",
      "Epoch 6/60\n",
      "1320/1320 [==============================] - 0s 332us/step - loss: 0.6584 - acc: 0.8765\n",
      "Epoch 7/60\n",
      "1320/1320 [==============================] - 0s 311us/step - loss: 0.6592 - acc: 0.8765\n",
      "Epoch 8/60\n",
      "1320/1320 [==============================] - 0s 307us/step - loss: 0.6728 - acc: 0.8765\n",
      "Epoch 9/60\n",
      "1320/1320 [==============================] - 0s 303us/step - loss: 0.7058 - acc: 0.8765\n",
      "Epoch 10/60\n",
      "1320/1320 [==============================] - 0s 310us/step - loss: 0.6962 - acc: 0.8765\n",
      "Epoch 11/60\n",
      "1320/1320 [==============================] - 0s 313us/step - loss: 0.6942 - acc: 0.8765\n",
      "Epoch 12/60\n",
      "1320/1320 [==============================] - 0s 302us/step - loss: 0.7097 - acc: 0.8765\n",
      "Epoch 13/60\n",
      "1320/1320 [==============================] - 0s 319us/step - loss: 0.7086 - acc: 0.8765\n",
      "Epoch 14/60\n",
      "1320/1320 [==============================] - 0s 302us/step - loss: 0.7070 - acc: 0.8765\n",
      "Epoch 15/60\n",
      "1320/1320 [==============================] - 0s 300us/step - loss: 0.7364 - acc: 0.8765\n",
      "Epoch 16/60\n",
      "1320/1320 [==============================] - 0s 308us/step - loss: 0.7223 - acc: 0.8765\n",
      "Epoch 17/60\n",
      "1320/1320 [==============================] - 0s 292us/step - loss: 0.7363 - acc: 0.8765\n",
      "Epoch 18/60\n",
      "1320/1320 [==============================] - 0s 302us/step - loss: 0.7280 - acc: 0.8765\n",
      "Epoch 19/60\n",
      "1320/1320 [==============================] - 0s 304us/step - loss: 0.7328 - acc: 0.8765\n",
      "Epoch 20/60\n",
      "1320/1320 [==============================] - 0s 296us/step - loss: 0.7374 - acc: 0.8765\n",
      "Epoch 21/60\n",
      "1320/1320 [==============================] - 0s 299us/step - loss: 0.7535 - acc: 0.8765\n",
      "Epoch 22/60\n",
      "1320/1320 [==============================] - 0s 303us/step - loss: 0.7360 - acc: 0.8765\n",
      "Epoch 23/60\n",
      "1320/1320 [==============================] - 0s 304us/step - loss: 0.7653 - acc: 0.8765\n",
      "Epoch 24/60\n",
      "1320/1320 [==============================] - 0s 300us/step - loss: 0.7544 - acc: 0.8765\n",
      "Epoch 25/60\n",
      "1320/1320 [==============================] - 0s 298us/step - loss: 0.7526 - acc: 0.8765\n",
      "Epoch 26/60\n",
      "1320/1320 [==============================] - 0s 309us/step - loss: 0.7533 - acc: 0.8765\n",
      "Epoch 27/60\n",
      "1320/1320 [==============================] - 0s 300us/step - loss: 0.7551 - acc: 0.8765\n",
      "Epoch 28/60\n",
      "1320/1320 [==============================] - 0s 306us/step - loss: 0.7544 - acc: 0.8765\n",
      "Epoch 29/60\n",
      "1320/1320 [==============================] - 0s 304us/step - loss: 0.7520 - acc: 0.8765\n",
      "Epoch 30/60\n",
      "1320/1320 [==============================] - 0s 299us/step - loss: 0.7503 - acc: 0.8765\n",
      "Epoch 31/60\n",
      "1320/1320 [==============================] - 0s 312us/step - loss: 0.7608 - acc: 0.8765\n",
      "Epoch 32/60\n",
      "1320/1320 [==============================] - 0s 306us/step - loss: 0.7561 - acc: 0.8765\n",
      "Epoch 33/60\n",
      "1320/1320 [==============================] - 0s 304us/step - loss: 0.7517 - acc: 0.8765\n",
      "Epoch 34/60\n",
      "1320/1320 [==============================] - 0s 318us/step - loss: 0.7530 - acc: 0.8765\n",
      "Epoch 35/60\n",
      "1320/1320 [==============================] - 0s 310us/step - loss: 0.7526 - acc: 0.8765\n",
      "Epoch 36/60\n",
      "1320/1320 [==============================] - 0s 311us/step - loss: 0.7485 - acc: 0.8765\n",
      "Epoch 37/60\n",
      "1320/1320 [==============================] - 0s 301us/step - loss: 0.7498 - acc: 0.8765\n",
      "Epoch 38/60\n",
      "1320/1320 [==============================] - 0s 300us/step - loss: 0.7528 - acc: 0.8765\n",
      "Epoch 39/60\n",
      "1320/1320 [==============================] - 0s 315us/step - loss: 0.7640 - acc: 0.8765\n",
      "Epoch 40/60\n",
      "1320/1320 [==============================] - 0s 310us/step - loss: 0.7518 - acc: 0.8765\n",
      "Epoch 41/60\n",
      "1320/1320 [==============================] - 0s 308us/step - loss: 0.7596 - acc: 0.8765\n",
      "Epoch 42/60\n",
      "1320/1320 [==============================] - 0s 303us/step - loss: 0.7640 - acc: 0.8765\n",
      "Epoch 43/60\n",
      "1320/1320 [==============================] - 0s 307us/step - loss: 0.7655 - acc: 0.8765\n",
      "Epoch 44/60\n",
      "1320/1320 [==============================] - 0s 309us/step - loss: 0.7792 - acc: 0.8765\n",
      "Epoch 45/60\n",
      "1320/1320 [==============================] - 0s 309us/step - loss: 0.7665 - acc: 0.8765\n",
      "Epoch 46/60\n",
      "1320/1320 [==============================] - 0s 312us/step - loss: 0.7677 - acc: 0.8765\n",
      "Epoch 47/60\n",
      "1320/1320 [==============================] - 0s 301us/step - loss: 0.7744 - acc: 0.8765\n",
      "Epoch 48/60\n",
      "1320/1320 [==============================] - 0s 300us/step - loss: 0.7689 - acc: 0.8765\n",
      "Epoch 49/60\n",
      "1320/1320 [==============================] - 0s 303us/step - loss: 0.7703 - acc: 0.8765\n",
      "Epoch 50/60\n",
      "1320/1320 [==============================] - 0s 327us/step - loss: 0.7871 - acc: 0.8765\n",
      "Epoch 51/60\n",
      "1320/1320 [==============================] - 0s 335us/step - loss: 0.7749 - acc: 0.8765\n",
      "Epoch 52/60\n",
      "1320/1320 [==============================] - 0s 344us/step - loss: 0.7742 - acc: 0.8765\n",
      "Epoch 53/60\n",
      "1320/1320 [==============================] - 0s 336us/step - loss: 0.7716 - acc: 0.8765\n",
      "Epoch 54/60\n",
      "1320/1320 [==============================] - 0s 302us/step - loss: 0.7809 - acc: 0.8765\n",
      "Epoch 55/60\n",
      "1320/1320 [==============================] - 0s 305us/step - loss: 0.7765 - acc: 0.8765\n",
      "Epoch 56/60\n",
      "1320/1320 [==============================] - 0s 310us/step - loss: 0.7848 - acc: 0.8765\n",
      "Epoch 57/60\n",
      "1320/1320 [==============================] - 0s 314us/step - loss: 0.7834 - acc: 0.8765\n",
      "Epoch 58/60\n",
      "1320/1320 [==============================] - 0s 309us/step - loss: 0.7840 - acc: 0.8765\n",
      "Epoch 59/60\n",
      "1320/1320 [==============================] - 0s 297us/step - loss: 0.7784 - acc: 0.8765\n",
      "Epoch 60/60\n",
      "1320/1320 [==============================] - 0s 300us/step - loss: 0.7818 - acc: 0.8765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2923e214e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras \n",
    "from keras import models\n",
    "from keras import layers\n",
    "network = models.Sequential()\n",
    "# input_shape : 输入张量的形状, (28*28,)表示1维度向量\n",
    "network.add(layers.Dense(32,activation='relu',input_shape=(x.shape[1],)))\n",
    "network.add(layers.Dense(len(le.classes_),activation='softmax'))\n",
    "# 4. 编译\n",
    "network.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "# 5. 训练模型\n",
    "network.fit(x,y,epochs=60,batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#保存词典\n",
    "with open('newdata/dict_save', 'wb') as f:                     \n",
    "    picklestring = pickle.dump(dictionary, f)\n",
    "#保存lda模型\n",
    "lda.save('newdata/lda.model')\n",
    "network.save('newdata/my_model.h5') # 保存模型\n",
    "network.save_weights('newdata/my_model_weights.h5') # 保存参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测 - tableau调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.04), (1, 0.04), (2, 0.04), (3, 0.04), (4, 0.04), (5, 0.04), (6, 0.04), (7, 0.04), (8, 0.04), (9, 0.04), (10, 0.04), (11, 0.04), (12, 0.04), (13, 0.04), (14, 0.04), (15, 0.04), (16, 0.04), (17, 0.04), (18, 0.04), (19, 0.04), (20, 0.04), (21, 0.04), (22, 0.04), (23, 0.04), (24, 0.04)]\n",
      "(0, 0.04)\n",
      "(1, 0.04)\n",
      "(2, 0.04)\n",
      "(3, 0.04)\n",
      "(4, 0.04)\n",
      "(5, 0.04)\n",
      "(6, 0.04)\n",
      "(7, 0.04)\n",
      "(8, 0.04)\n",
      "(9, 0.04)\n",
      "(10, 0.04)\n",
      "(11, 0.04)\n",
      "(12, 0.04)\n",
      "(13, 0.04)\n",
      "(14, 0.04)\n",
      "(15, 0.04)\n",
      "(16, 0.04)\n",
      "(17, 0.04)\n",
      "(18, 0.04)\n",
      "(19, 0.04)\n",
      "(20, 0.04)\n",
      "(21, 0.04)\n",
      "(22, 0.04)\n",
      "(23, 0.04)\n",
      "(24, 0.04)\n",
      "[0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04\n",
      " 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "from keras.models import load_model\n",
    "\n",
    "def get_stop_words():\n",
    "    with open('data/stop_words_utf8.txt') as f:\n",
    "        content = f.readlines()\n",
    "        stopwords = [w.strip() for w in content]\n",
    "        return stopwords\n",
    "\n",
    "# 全角转换成半角\n",
    "def strQ2B(ustring):\n",
    "    '''全角转半角\n",
    "    ustring : 需要转换的字符串\n",
    "    '''\n",
    "    ss = ''\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # 全角空格直接转换\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全角字符（除空格）根据关系转化\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss = ss + rstring\n",
    "    return ss\n",
    "# 对corpus中每个文章分词后滤出停用词\n",
    "def cut(doc):\n",
    "    content = list(jieba.cut(doc))\n",
    "    stopwords = get_stop_words()\n",
    "    return '/'.join([w for w in content if w not in stopwords and w!=' '])\n",
    "def handle_desc(desc):\n",
    "    desc = strQ2B(desc)\n",
    "    cut = jieba.cut(desc)\n",
    "    stopwords = get_stop_words()\n",
    "    return [w for w in cut if w not in stopwords and w!=' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "山东省\n",
      "['红头文件可修改..']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/devkits/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': '旧动能',\n",
       " '经营范围': '道路货物运输(普通货运);三类汽车维修(车身清洁维护);第一类压力容器、第二类低中压容器的设计、制造、销售,工业氧气(以上经营项目有效期限以许可证为准);金属成型机床设备、金属切削机床设备、工业自动控制系统装置、铸造机械设备、金属切割及焊接设备、建材及环境保护专用设备、机床附件、配电开关控制设备、塑料工业设备、包装机械设备、模具的设计、制造、销售;机床设备安装调试、维修改造;A级起重机械安装、GC2压力管道安装(以上凭资质证经营);机械零部件加工;金属材料、铸件、五金交电、橡胶制品、木制品、工夹量仪、汽车、汽车配件的销售;进出口业务;装卸服务;机械设备技术开发;企业管理咨询;计算机信息技术服务;软件开发;检测技术服务;经济贸易代理;职业技能鉴定;房屋租赁;场地租赁;物业管理服务;会议会展服务;分支机构经营:金属材料的焊接、锻造和热处理;提供培训场地、住宿,餐饮,酒水、卷烟的零售(以上凭许可证经营)。(依法须经批准的项目,经相关部门批准后方可开展经营活动)。',\n",
       " '所属城市': '山东省',\n",
       " '公司名称': '济南二机床集团有限公司技术中心',\n",
       " '红头文件描述项目': '红头文件可修改..'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def getredItem(city):\n",
    "    df = pd.read_csv(\"newdata/redhead.csv\",delimiter=\"$\",header=None)\n",
    "    df.columns = [\"地市\",\"红头文件描述\"]\n",
    "    res = df[df[\"地市\"]==city][\"红头文件描述\"].tolist()\n",
    "    print(res)\n",
    "    return res[0]\n",
    "getredItem(\"山东省\")\n",
    "\n",
    "def getResult(corpName,topic_num):\n",
    "    res_dict = {}\n",
    "    with open('newdata/dict_save', 'rb') as f:\n",
    "        load_dictionary = pickle.load(f)   # read file and build object\n",
    "    from gensim import models\n",
    "    load_lda = models.ldamodel.LdaModel.load('newdata/lda.model')\n",
    "\n",
    "    model = load_model('newdata/my_model.h5')\n",
    "    model.load_weights('newdata/my_model_weights.h5')\n",
    "    \n",
    "    alldf = pd.read_csv(\"newdata/input.csv\",index_col=0)\n",
    "    alldf = alldf[alldf[\"企业名称\"]==corpName]\n",
    "    desc = alldf[\"经营业务范围\"][0]\n",
    "    \n",
    "    a = load_dictionary.doc2bow(handle_desc(desc))\n",
    "    topic_distribute = load_lda[a]\n",
    "#     print(topic_distribute)\n",
    "    x_test = np.zeros((topic_num,))\n",
    "    for tupl in topic_distribute:\n",
    "#         print(tupl)\n",
    "        x_test[tupl[0]]=tupl[1]\n",
    "    res = model.predict(x_test.reshape(1,topic_num))\n",
    "    res_dict[\"label\"] = le.inverse_transform([np.argmax(res[0])])[0]\n",
    "    res_dict[\"经营范围\"] = desc\n",
    "    res_dict[\"所属城市\"] = alldf[\"所在城市\"][0]\n",
    "    print(alldf[\"所在城市\"][0])\n",
    "    res_dict[\"公司名称\"] = corpName\n",
    "    res_dict[\"红头文件描述项目\"] = getredItem(alldf[\"所在城市\"][0])\n",
    "    \n",
    "    return res_dict\n",
    "    \n",
    "topic_num = 25\n",
    "corpName = \"济南二机床集团有限公司技术中心\"\n",
    "getResult(corpName,topic_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 附录: 整理爬去的数据为输入格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = pd.read_csv(\"newdata/qichacha.csv\",index_col=0)\n",
    "input1 = input1[[\"公司名\",\"统一社会信用代码\",\"所属地区\",\"经营范围\"]]\n",
    "input1.columns = [\"企业名称\",\"统一信用代码\",\"所在城市\",\"经营业务范围\"]\n",
    "input1[\"label\"] = \"旧动能\"\n",
    "input1.head()\n",
    "pos_df = pd.read_excel(\"pos.xlsx\")\n",
    "pos_df = pd.DataFrame({\"公司名称\":pos_df[\"公司名称\"],\n",
    "                       \"经营范围\":pos_df[\"经营范围\"],\n",
    "                       \"企业分类\":pos_df[\"企业分类\"]})\n",
    "pos_df = pos_df.dropna(how=\"any\",axis=0)\n",
    "pos_df.columns = [\"企业名称\",\"经营业务范围\",\"label\"]\n",
    "pos_df[\"统一信用代码\"] = \"-\"\n",
    "pos_df[\"所在城市\"] = \"山东省\"\n",
    "pos_df.head()\n",
    "alldf = pd.concat([pos_df,input1],axis=0)\n",
    "alldf.to_csv(\"newdata/input.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
