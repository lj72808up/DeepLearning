{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 什么是用户画像\n",
    "#### 一. User Profile \n",
    "1. 推荐系统在匹配用户和物品前, 需要对用户和物品进行向量化才能计算  \n",
    "2. 对用户向量化后的结果就是User Profile, 俗称\"用户画像\". 所以用户画像并非必须属于人类可读的维度  \n",
    "3. 召回和排序  \n",
    " 1. 因为物品数量众多, 无法对所有物品估计评分. 所有需要预先筛选一部分物品来减少计算量. 这个筛选的过程就是召回.  \n",
    " 2. 用户画像(向量)也会被用于物品召回阶段\n",
    " \n",
    "#### 二. 用户画像的构建方法  \n",
    "1. 查户口  \n",
    " 直接使用原始数据作为用户画像的内容. 如'注册资料','购买历史','阅读历史'  \n",
    "2. 堆积历史数据  \n",
    " 堆积历史数据, 做统计工作. 可以从历史数据中挖掘标签, 在标签上做统计  \n",
    "3. 黑盒子  \n",
    " 用机器学习,深度学习的方法得到人类无关理解的稠密向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 从文本中挖掘用户画像\n",
    "对于一个早期推荐系统, 离不开为用户构建一个初级画像. 而这个初级画像, 往往是从文本数据中得来\n",
    "#### 一. 文本中包含的可用数据 \n",
    "1. 用户端 \n",
    "  1. 注册资料中的姓名, 个人签名  \n",
    "  2. 用户发表的评论, 动态, 日记等  \n",
    "  3. 聊天记录  \n",
    "2. 物品端 - 用于构建物品画像,从而丰富用户画像 \n",
    "  1. 物品的标题, 描述  \n",
    "  2. 物品本身的内容  \n",
    "  3. 物品的其他基本属性文本\n",
    "  \n",
    "#### 二. 如何使用文本数据构建用户画像\n",
    "1. 假设我们已得到用户和物品的文本数据, 要想从这些文本数据中得到用户画像需要两步:  \n",
    "  1. 将非结构化的文本数据结构化  \n",
    "  2. 根据用户的行为数据, 把物品的结构化结果传递给用户,与用户自身的结构化数据合并\n",
    "2. 非结构化的文本数据结构化  \n",
    " 非结构化的文本数据结构化, 主要是使用NLP技术:  \n",
    "  1. 关键词提取 : TF-IDF,TextRank  \n",
    "  2. 实体识别 : HMM,条件随机场  \n",
    "  3. 内容分类 : SVm,FastText  \n",
    "  5. 主题模型 : LDA \n",
    "  6. word embedding\n",
    "\n",
    "#### 三. 关键词提取  \n",
    "从文本中提取关键词. 是最基本的标签来源, 也为其他文本数据提供分析基础. 常用的有`TF-IDF`和`TextRank`  \n",
    "1. `TF-IDF`  \n",
    "   1. `TF-IDF`使用'词频(某个文本中出现的次数)\\*逆文档(所有文档中出现的一个比率)'计算每个文档中, 每个单词的权重$${ IDF }_{ i,w }={ n }_{ i,w }*\\log { \\frac { { N }_{ w } }{ { n }_{ i,w }+1 }  } $$ \n",
    "   2. 然后计算每个单词在corpus中权值的均值.大于这个均值的就是该文档的主题词\n",
    "2. `TextRank`  \n",
    " [https://www.letiantian.me/2014-12-01-text-rank/](https://www.letiantian.me/2014-12-01-text-rank/)\n",
    " \n",
    "#### 四. 实体识别  \n",
    "实体识别是NLP中的序列标注问题, 和分词,词性标注属于同一类问题. 序列标注问题的算法一般是`HMM`和`条件随机场`\n",
    "\n",
    "\n",
    "#### 五. 内容分类  \n",
    "门户网站时代, 每个门户网站都有自己的频道体系.例如\"体育,财经,娱乐\"等频道. 那是后的文本都是长文本  \n",
    "如今UGC当道的时代, 大都是短文本.短文本分类的经典方法是SVM和FastText\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3 标签选择\n",
    "如上所说, 我们通过'关键词提取','实体识别','内容分类','主题模型'处理成结构化数据后, 得到了一些列标签. 那么哪些标签和用户是否消费物品相关呢, 就需要进行标签选择.如果把用户是否消费这个物品看成用户对分人任务进行的标注, 那么标签选择就等同于特征选择. 主要有卡方检验和消息增益\n",
    "\n",
    "#### 一. 卡方检验\n",
    "1. 卡方检验对每个标签(特征)进行计算, 得到这个标签(特征)和用户消费物品这个结果的相关程度  \n",
    "2. 卡方检验的计算步骤  \n",
    " 1. 要计算标签$W_i$和类别$c_j$的相关度, 需要统计四类数据  \n",
    " <img src='img/kafangjianyan.png' width='60%' height='60%'>  \n",
    " 2. 卡房值$${ x }^{ 2 }\\left( { w }_{ i },{ c }_{ j } \\right) =\\frac { N\\left( AD-BC \\right)  }{ \\left( A+C \\right) \\left( B+D \\right) \\left( A+B \\right) \\left( C+D \\right)  } $$   \n",
    "3. 标签选择, 就是选择卡方值最高的前N个标签\n",
    "\n",
    "#### 二. 消息增益\n",
    "1. 消息增益用来筛选特征, 就好像只有一层的决策树, 选择哪个属性作为第一个内部节点.  \n",
    "2. 选择消息增益最高的几个标签(特征)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
